{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021edb3d",
   "metadata": {},
   "source": [
    "physionetが公開しているデータセットからデータを抽出し、睡眠段階を可視化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ec153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default location ~/mne_data for PHYSIONET_SLEEP...\n",
      "Raw data files type: <class 'list'>\n",
      "Raw data files: [['/Users/mizuno_shin/mne_data/physionet-sleep-data/SC4001E0-PSG.edf', '/Users/mizuno_shin/mne_data/physionet-sleep-data/SC4001EC-Hypnogram.edf']]\n",
      "使用するファイルパス: /Users/mizuno_shin/mne_data/physionet-sleep-data/SC4001E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/mizuno_shin/mne_data/physionet-sleep-data/SC4001E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 7949999  =      0.000 ... 79499.990 secs...\n",
      "アノテーションファイルが利用できません - 生データのみで解析を続行\n",
      "データの長さ: 79500.0 秒\n",
      "サンプリング周波数: 100.0 Hz\n",
      "チャンネル数: 7\n",
      "チャンネル名: ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n",
      "使用するEOGチャンネル: ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
      "使用するEEGチャンネル: ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "特徴量を抽出中...\n",
      "\n",
      "=== REM睡眠検知結果 ===\n",
      "総記録時間: 2649.0 分\n",
      "検知されたREM睡眠時間: 662.5 分\n",
      "REM睡眠の割合: 25.0%\n",
      "REM睡眠エピソード数: 366\n",
      "\n",
      "=== 詳細統計 ===\n",
      "平均REMスコア: -0.000\n",
      "REMスコア標準偏差: 2.414\n",
      "検知閾値: 1.418\n",
      "最長REM連続時間: 71.5 分\n",
      "\n",
      "=== ファイル保存完了 ===\n",
      "JSON結果: rem_analysis_results.json\n",
      "詳細CSV: rem_detailed_analysis.csv\n",
      "使用チャンネル - EOG: ['EEG Fpz-Cz', 'EEG Pz-Oz'], EEG: ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
      "\n",
      "=== 統合システム準備完了 ===\n",
      "CBTシステムとの統合準備が完了しました。\n",
      "夢の報告を受け付ける準備ができています。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.datasets import sleep_physionet\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "# データの取得\n",
    "subjects = [0]\n",
    "recording = [1]\n",
    "\n",
    "# PhysioNetの睡眠データセットを取得\n",
    "try:\n",
    "    # データファイルを取得\n",
    "    raw_fnames = sleep_physionet.age.fetch_data(subjects=subjects, recording=recording)\n",
    "\n",
    "    # ファイルパスの確認とデバッグ\n",
    "    print(f\"Raw data files type: {type(raw_fnames)}\")\n",
    "    print(f\"Raw data files: {raw_fnames}\")\n",
    "\n",
    "    # 最初のファイルパスを取得\n",
    "    if isinstance(raw_fnames, list) and len(raw_fnames) > 0:\n",
    "        if isinstance(raw_fnames[0], list):\n",
    "            raw_file_path = raw_fnames[0][0]  # ネストされたリストの場合\n",
    "        else:\n",
    "            raw_file_path = raw_fnames[0]\n",
    "    else:\n",
    "        raise ValueError(\"データファイルが見つかりません\")\n",
    "\n",
    "    print(f\"使用するファイルパス: {raw_file_path}\")\n",
    "\n",
    "    # アノテーションファイルの処理は後回し\n",
    "    annotation_fname = None\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"データ取得エラー: {e}\")\n",
    "    # フォールバック: 別の被験者やrecordingを試す\n",
    "    try:\n",
    "        subjects = [0]\n",
    "        recording = [2]  # recording [2]を試す\n",
    "        raw_fnames = sleep_physionet.age.fetch_data(subjects=subjects, recording=recording)\n",
    "        if isinstance(raw_fnames[0], list):\n",
    "            raw_file_path = raw_fnames[0][0]\n",
    "        else:\n",
    "            raw_file_path = raw_fnames[0]\n",
    "        annotation_fname = None\n",
    "    except:\n",
    "        print(\"すべてのフォールバックオプションが失敗しました\")\n",
    "        raise\n",
    "\n",
    "# データの読み込み\n",
    "raw = mne.io.read_raw_edf(raw_file_path, preload=True, stim_channel=None)\n",
    "\n",
    "# アノテーションが利用可能な場合のみ読み込み\n",
    "if annotation_fname:\n",
    "    try:\n",
    "        annotations = mne.read_annotations(annotation_fname)\n",
    "        raw.set_annotations(annotations)\n",
    "        print(\"アノテーションを適用しました\")\n",
    "    except:\n",
    "        print(\"アノテーションの読み込みに失敗しました\")\n",
    "else:\n",
    "    print(\"アノテーションファイルが利用できません - 生データのみで解析を続行\")\n",
    "\n",
    "print(f\"データの長さ: {raw.times[-1]:.1f} 秒\")\n",
    "print(f\"サンプリング周波数: {raw.info['sfreq']} Hz\")\n",
    "print(f\"チャンネル数: {len(raw.ch_names)}\")\n",
    "print(f\"チャンネル名: {raw.ch_names}\")\n",
    "\n",
    "# 利用可能なチャンネルを確認してEOGとEEGチャンネルを選択\n",
    "available_channels = raw.ch_names\n",
    "\n",
    "# EOGチャンネルの検索と選択\n",
    "eog_possible = ['EOG horizontal', 'EOG vertical', 'EOG', 'EOG1', 'EOG2']\n",
    "eog_channels = [ch for ch in eog_possible if ch in available_channels]\n",
    "\n",
    "if len(eog_channels) == 0:\n",
    "    # EOGチャンネルが見つからない場合、EEGチャンネルから代用\n",
    "    print(\"EOGチャンネルが見つかりません。EEGチャンネルを使用します。\")\n",
    "    eog_channels = [ch for ch in available_channels if 'EEG' in ch][:2]\n",
    "\n",
    "# チャンネルが不足している場合の処理\n",
    "if len(eog_channels) < 2:\n",
    "    eog_channels = available_channels[:2]  # 最初の2チャンネルを使用\n",
    "\n",
    "print(f\"使用するEOGチャンネル: {eog_channels}\")\n",
    "\n",
    "# EEGチャンネルの検索と選択\n",
    "eeg_possible = ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EEG C3-A2', 'EEG C4-A1']\n",
    "eeg_channels = [ch for ch in eeg_possible if ch in available_channels]\n",
    "\n",
    "if len(eeg_channels) == 0:\n",
    "    # 指定されたEEGチャンネルが見つからない場合、利用可能なEEGチャンネルを使用\n",
    "    eeg_channels = [ch for ch in available_channels if 'EEG' in ch][:2]\n",
    "\n",
    "# チャンネルが不足している場合の処理\n",
    "if len(eeg_channels) < 2:\n",
    "    # EOGチャンネルとは異なるチャンネルを選択\n",
    "    remaining_channels = [ch for ch in available_channels if ch not in eog_channels]\n",
    "    eeg_channels = remaining_channels[:2]\n",
    "\n",
    "print(f\"使用するEEGチャンネル: {eeg_channels}\")\n",
    "\n",
    "# チャンネルデータの取得\n",
    "eog_data = raw.copy().pick_channels(eog_channels[:2])  # 最大2チャンネル\n",
    "eeg_data = raw.copy().pick_channels(eeg_channels[:2])  # 最大2チャンネル\n",
    "\n",
    "# REM睡眠検知のための特徴量抽出\n",
    "def extract_rem_features(raw_data, window_size=30, overlap=0.5):\n",
    "    \"\"\"\n",
    "    REM睡眠検知のための特徴量を抽出\n",
    "    \"\"\"\n",
    "    sfreq = raw_data.info['sfreq']\n",
    "    window_samples = int(window_size * sfreq)\n",
    "    step_samples = int(window_samples * (1 - overlap))\n",
    "\n",
    "    features = []\n",
    "    times = []\n",
    "\n",
    "    for start in range(0, len(raw_data.times) - window_samples, step_samples):\n",
    "        end = start + window_samples\n",
    "        time_center = raw_data.times[start + window_samples // 2]\n",
    "\n",
    "        # EOGデータの取得\n",
    "        eog_segment = eog_data.get_data()[:, start:end]\n",
    "\n",
    "        # EEGデータの取得\n",
    "        eeg_segment = eeg_data.get_data()[:, start:end]\n",
    "\n",
    "        # EOG特徴量（急速眼球運動の検知）\n",
    "        eog_std = np.std(eog_segment, axis=1)\n",
    "        eog_range = np.ptp(eog_segment, axis=1)\n",
    "\n",
    "        # EEG特徴量（低振幅・混合周波数の検知）\n",
    "        eeg_power_bands = {}\n",
    "        for i, ch_data in enumerate(eeg_segment):\n",
    "            freqs, psd = signal.welch(ch_data, sfreq, nperseg=min(256, len(ch_data)))\n",
    "\n",
    "            # 周波数帯域のパワー計算\n",
    "            delta_power = np.mean(psd[(freqs >= 0.5) & (freqs < 4)])\n",
    "            theta_power = np.mean(psd[(freqs >= 4) & (freqs < 8)])\n",
    "            alpha_power = np.mean(psd[(freqs >= 8) & (freqs < 13)])\n",
    "            beta_power = np.mean(psd[(freqs >= 13) & (freqs < 30)])\n",
    "\n",
    "            eeg_power_bands[f'ch{i}_delta'] = delta_power\n",
    "            eeg_power_bands[f'ch{i}_theta'] = theta_power\n",
    "            eeg_power_bands[f'ch{i}_alpha'] = alpha_power\n",
    "            eeg_power_bands[f'ch{i}_beta'] = beta_power\n",
    "\n",
    "        # 特徴量の組み合わせ（ゼロ除算回避）\n",
    "        feature_vector = [\n",
    "            np.mean(eog_std),  # EOG標準偏差の平均\n",
    "            np.mean(eog_range),  # EOG範囲の平均\n",
    "            eeg_power_bands['ch0_theta'] / (eeg_power_bands['ch0_delta'] + 1e-10),  # シータ/デルタ比\n",
    "            eeg_power_bands['ch1_theta'] / (eeg_power_bands['ch1_delta'] + 1e-10),\n",
    "            np.mean([eeg_power_bands['ch0_alpha'], eeg_power_bands['ch1_alpha']]),  # アルファ波パワー\n",
    "            np.mean([eeg_power_bands['ch0_beta'], eeg_power_bands['ch1_beta']])   # ベータ波パワー\n",
    "        ]\n",
    "\n",
    "        features.append(feature_vector)\n",
    "        times.append(time_center)\n",
    "\n",
    "    return np.array(features), np.array(times)\n",
    "\n",
    "# 特徴量抽出\n",
    "print(\"特徴量を抽出中...\")\n",
    "features, feature_times = extract_rem_features(raw)\n",
    "\n",
    "# REM睡眠の簡易検知アルゴリズム\n",
    "def detect_rem_sleep(features, threshold_percentile=75):\n",
    "    \"\"\"\n",
    "    特徴量を基にREM睡眠を検知\n",
    "    \"\"\"\n",
    "    # 特徴量の正規化\n",
    "    scaler = StandardScaler()\n",
    "    features_normalized = scaler.fit_transform(features)\n",
    "\n",
    "    # REM睡眠スコアの計算（EOG活動 + 低デルタ波活動）\n",
    "    eog_score = features_normalized[:, 0] + features_normalized[:, 1]  # EOG活動\n",
    "    theta_delta_ratio = features_normalized[:, 2] + features_normalized[:, 3]  # シータ/デルタ比\n",
    "\n",
    "    rem_score = eog_score + theta_delta_ratio\n",
    "\n",
    "    # 閾値による検知\n",
    "    threshold = np.percentile(rem_score, threshold_percentile)\n",
    "    rem_detected = rem_score > threshold\n",
    "\n",
    "    return rem_detected, rem_score\n",
    "\n",
    "# REM睡眠検知\n",
    "rem_detected, rem_score = detect_rem_sleep(features)\n",
    "\n",
    "# 統計情報の計算と出力\n",
    "total_rem_time = np.sum(rem_detected) * 30 / 60  # 分単位\n",
    "total_recording_time = len(feature_times) * 30 / 60  # 分単位\n",
    "rem_percentage = (total_rem_time / total_recording_time) * 100\n",
    "rem_episodes = int(np.sum(np.diff(rem_detected.astype(int)) == 1))\n",
    "\n",
    "print(f\"\\n=== REM睡眠検知結果 ===\")\n",
    "print(f\"総記録時間: {total_recording_time:.1f} 分\")\n",
    "print(f\"検知されたREM睡眠時間: {total_rem_time:.1f} 分\")\n",
    "print(f\"REM睡眠の割合: {rem_percentage:.1f}%\")\n",
    "print(f\"REM睡眠エピソード数: {rem_episodes}\")\n",
    "\n",
    "# 詳細な統計情報\n",
    "print(f\"\\n=== 詳細統計 ===\")\n",
    "print(f\"平均REMスコア: {np.mean(rem_score):.3f}\")\n",
    "print(f\"REMスコア標準偏差: {np.std(rem_score):.3f}\")\n",
    "print(f\"検知閾値: {np.percentile(rem_score, 75):.3f}\")\n",
    "print(f\"最長REM連続時間: {np.max([len(list(g)) for k, g in __import__('itertools').groupby(rem_detected) if k]) * 0.5:.1f} 分\")\n",
    "\n",
    "# データをJSONで保存（後の統合システムで使用）\n",
    "sleep_data = {\n",
    "    \"session_id\": \"rem_analysis_001\",\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    \"total_recording_time\": float(total_recording_time),\n",
    "    \"rem_time\": float(total_rem_time),\n",
    "    \"rem_percentage\": float(rem_percentage),\n",
    "    \"rem_episodes\": rem_episodes,\n",
    "    \"channels_used\": {\n",
    "        \"eog\": eog_channels,\n",
    "        \"eeg\": eeg_channels\n",
    "    },\n",
    "    \"features_shape\": list(features.shape),\n",
    "    \"rem_statistics\": {\n",
    "        \"mean_score\": float(np.mean(rem_score)),\n",
    "        \"std_score\": float(np.std(rem_score)),\n",
    "        \"threshold\": float(np.percentile(rem_score, 75)),\n",
    "        \"max_continuous_rem_minutes\": float(np.max([len(list(g)) for k, g in __import__('itertools').groupby(rem_detected) if k]) * 0.5)\n",
    "    },\n",
    "    \"plot_saved\": False,\n",
    "    \"analysis_method\": \"EOG_EEG_feature_extraction\"\n",
    "}\n",
    "\n",
    "# 結果をJSONファイルとして保存\n",
    "with open('/dreamdive-Baku/rem_analysis_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sleep_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# CSVでも詳細データを保存\n",
    "detailed_results = pd.DataFrame({\n",
    "    'time_hours': feature_times / 3600,\n",
    "    'rem_score': rem_score,\n",
    "    'rem_detected': rem_detected.astype(int),\n",
    "    'eog_std': features[:, 0],\n",
    "    'eog_range': features[:, 1],\n",
    "    'theta_delta_ratio_ch0': features[:, 2],\n",
    "    'theta_delta_ratio_ch1': features[:, 3],\n",
    "    'alpha_power': features[:, 4],\n",
    "    'beta_power': features[:, 5]\n",
    "})\n",
    "\n",
    "detailed_results.to_csv('/dreamdive-Baku/rem_detailed_analysis.csv', index=False)\n",
    "\n",
    "print(f\"\\n=== ファイル保存完了 ===\")\n",
    "print(f\"JSON結果: rem_analysis_results.json\")\n",
    "print(f\"詳細CSV: rem_detailed_analysis.csv\")\n",
    "print(f\"使用チャンネル - EOG: {eog_channels}, EEG: {eeg_channels}\")\n",
    "\n",
    "# CBTシステムとの統合用データ準備\n",
    "integration_data = {\n",
    "    \"sleep_session\": sleep_data,\n",
    "    \"ready_for_integration\": True,\n",
    "    \"next_step\": \"dream_report_input\"\n",
    "}\n",
    "\n",
    "print(f\"\\n=== 統合システム準備完了 ===\")\n",
    "print(f\"CBTシステムとの統合準備が完了しました。\")\n",
    "print(f\"夢の報告を受け付ける準備ができています。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import kaleido  # noqa\n",
    "\n",
    "df = detailed_results.copy()\n",
    "threshold = float(np.percentile(rem_score, 75))\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.03,\n",
    "    subplot_titles=(\"REMスコアと閾値\", \"Theta/Delta 比（ch0/ch1）\", \"EOG 指標（std/range）\")\n",
    ")\n",
    "\n",
    "# Row1: REMスコア + 閾値\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[\"time_hours\"], y=df[\"rem_score\"], name=\"REM score\", line=dict(color=\"#2E86DE\")\n",
    "), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[\"time_hours\"], y=[threshold]*len(df), name=\"threshold(p75)\", line=dict(color=\"#E74C3C\", dash=\"dash\")\n",
    "), row=1, col=1)\n",
    "\n",
    "# REM検知区間をシェーディング\n",
    "mask = df[\"rem_detected\"] == 1\n",
    "segments = []\n",
    "in_seg = False\n",
    "start_t = None\n",
    "for i in range(len(mask)):\n",
    "    if mask.iloc[i] and not in_seg:\n",
    "        in_seg = True\n",
    "        start_t = df[\"time_hours\"].iloc[i]\n",
    "    if in_seg and (i == len(mask)-1 or not mask.iloc[i+1]):\n",
    "        end_t = df[\"time_hours\"].iloc[i]\n",
    "        segments.append((start_t, end_t))\n",
    "        in_seg = False\n",
    "\n",
    "for s, e in segments:\n",
    "    fig.add_vrect(x0=s, x1=e, fillcolor=\"rgba(0,150,255,0.12)\", line_width=0, layer=\"below\")\n",
    "\n",
    "# Row2: Theta/Delta\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[\"time_hours\"], y=df[\"theta_delta_ratio_ch0\"], name=\"Theta/Delta ch0\", line=dict(color=\"#27AE60\")\n",
    "), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[\"time_hours\"], y=df[\"theta_delta_ratio_ch1\"], name=\"Theta/Delta ch1\", line=dict(color=\"#F39C12\")\n",
    "), row=2, col=1)\n",
    "\n",
    "# Row3: EOG\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[\"time_hours\"], y=df[\"eog_std\"], name=\"EOG std\", line=dict(color=\"#8E44AD\")\n",
    "), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[\"time_hours\"], y=df[\"eog_range\"], name=\"EOG range\", line=dict(color=\"#16A085\")\n",
    "), row=3, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"経過時間 [hours]\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"スコア\", row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"REM検知 可視化（Plotly）\",\n",
    "    height=900, width=1200, legend_orientation=\"h\", legend_y= -0.06, margin=dict(l=60, r=20, t=60, b=60)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 保存（HTMLは常に、PNGはkaleidoが必要）\n",
    "out_dir = \"/dreamdive-Baku\"\n",
    "html_path = os.path.join(out_dir, \"rem_analysis_plot.html\")\n",
    "png_path = os.path.join(out_dir, \"rem_analysis_plot.png\")\n",
    "\n",
    "pio.write_html(fig, file=html_path, auto_open=False, include_plotlyjs=\"cdn\")\n",
    "\n",
    "png_saved = False\n",
    "try:\n",
    "    pio.write_image(fig, png_path, width=1400, height=900, scale=2)\n",
    "    png_saved = True\n",
    "except Exception:\n",
    "    print(\"PNG保存には kaleido が必要です: pip install -U kaleido\")\n",
    "\n",
    "sleep_data[\"plot_saved\"] = bool(png_saved)\n",
    "with open('/dreamdive-Baku/rem_analysis_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sleep_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"可視化HTML: {html_path}\")\n",
    "if png_saved:\n",
    "    print(f\"可視化PNG : {png_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c237ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
